{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b502105e",
   "metadata": {},
   "source": [
    "# First LangChain Program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4b2228e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai in c:\\users\\bharanidharan.a\\appdata\\local\\anaconda3\\lib\\site-packages (1.42.0)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\bharanidharan.a\\appdata\\local\\anaconda3\\lib\\site-packages (from openai) (4.2.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\bharanidharan.a\\appdata\\local\\anaconda3\\lib\\site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\bharanidharan.a\\appdata\\local\\anaconda3\\lib\\site-packages (from openai) (0.27.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in c:\\users\\bharanidharan.a\\appdata\\local\\anaconda3\\lib\\site-packages (from openai) (0.5.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in c:\\users\\bharanidharan.a\\appdata\\local\\anaconda3\\lib\\site-packages (from openai) (2.8.2)\n",
      "Requirement already satisfied: sniffio in c:\\users\\bharanidharan.a\\appdata\\local\\anaconda3\\lib\\site-packages (from openai) (1.3.0)\n",
      "Requirement already satisfied: tqdm>4 in c:\\users\\bharanidharan.a\\appdata\\local\\anaconda3\\lib\\site-packages (from openai) (4.66.4)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in c:\\users\\bharanidharan.a\\appdata\\local\\anaconda3\\lib\\site-packages (from openai) (4.11.0)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\bharanidharan.a\\appdata\\local\\anaconda3\\lib\\site-packages (from anyio<5,>=3.5.0->openai) (3.7)\n",
      "Requirement already satisfied: certifi in c:\\users\\bharanidharan.a\\appdata\\local\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (2024.6.2)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\bharanidharan.a\\appdata\\local\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (1.0.5)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\bharanidharan.a\\appdata\\local\\anaconda3\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\bharanidharan.a\\appdata\\local\\anaconda3\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in c:\\users\\bharanidharan.a\\appdata\\local\\anaconda3\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (2.20.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\bharanidharan.a\\appdata\\local\\anaconda3\\lib\\site-packages (from tqdm>4->openai) (0.4.6)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5bf38016",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import os \n",
    "import getpass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3bf476d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " ········\n"
     ]
    }
   ],
   "source": [
    "os.environ['OPENAI_API_KEY'] = getpass.getpass()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9d9f9bea",
   "metadata": {},
   "outputs": [],
   "source": [
    "openai.api_key = os.getenv('OPENAI_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1b2bf11e-ecfc-4042-ae88-140f8835657f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d966d047",
   "metadata": {},
   "outputs": [],
   "source": [
    "reply = client.chat.completions.create(\n",
    "  model=\"gpt-3.5-turbo\",\n",
    "  max_tokens =100,\n",
    "  messages=[\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"You are a helpful assistant.\"\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"What is a large language model?\",\n",
    "        }\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "240945e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatCompletion(id='chatcmpl-A19pO98ScViPvFeVKJMdhzEI0wBoO', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='A large language model is a type of artificial intelligence that is designed to understand and generate human language. These models are trained on huge amounts of text data to learn the patterns and structures of language. They can be used for a wide range of natural language processing tasks such as text generation, translation, summarization, and more. Large language models are capable of generating human-like text and have demonstrated impressive performance on various language-related tasks.', refusal=None, role='assistant', function_call=None, tool_calls=None))], created=1724839470, model='gpt-3.5-turbo-0125', object='chat.completion', service_tier=None, system_fingerprint=None, usage=CompletionUsage(completion_tokens=86, prompt_tokens=24, total_tokens=110))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7f7b9d01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A large language model is a type of artificial intelligence that is designed to understand and generate human language. These models are trained on huge amounts of text data to learn the patterns and structures of language. They can be used for a wide range of natural language processing tasks such as text generation, translation, summarization, and more. Large language models are capable of generating human-like text and have demonstrated impressive performance on various language-related tasks.\n"
     ]
    }
   ],
   "source": [
    "print(reply.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d524ae06",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8b9163f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain in c:\\users\\bharanidharan.a\\appdata\\local\\anaconda3\\lib\\site-packages (0.2.14)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\bharanidharan.a\\appdata\\local\\anaconda3\\lib\\site-packages (from langchain) (6.0.1)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in c:\\users\\bharanidharan.a\\appdata\\local\\anaconda3\\lib\\site-packages (from langchain) (2.0.30)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in c:\\users\\bharanidharan.a\\appdata\\local\\anaconda3\\lib\\site-packages (from langchain) (3.9.5)\n",
      "Requirement already satisfied: langchain-core<0.3.0,>=0.2.32 in c:\\users\\bharanidharan.a\\appdata\\local\\anaconda3\\lib\\site-packages (from langchain) (0.2.35)\n",
      "Requirement already satisfied: langchain-text-splitters<0.3.0,>=0.2.0 in c:\\users\\bharanidharan.a\\appdata\\local\\anaconda3\\lib\\site-packages (from langchain) (0.2.2)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in c:\\users\\bharanidharan.a\\appdata\\local\\anaconda3\\lib\\site-packages (from langchain) (0.1.104)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.26.0 in c:\\users\\bharanidharan.a\\appdata\\local\\anaconda3\\lib\\site-packages (from langchain) (1.26.4)\n",
      "Requirement already satisfied: pydantic<3,>=1 in c:\\users\\bharanidharan.a\\appdata\\local\\anaconda3\\lib\\site-packages (from langchain) (2.8.2)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\bharanidharan.a\\appdata\\local\\anaconda3\\lib\\site-packages (from langchain) (2.32.2)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in c:\\users\\bharanidharan.a\\appdata\\local\\anaconda3\\lib\\site-packages (from langchain) (8.2.2)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\bharanidharan.a\\appdata\\local\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.2.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\bharanidharan.a\\appdata\\local\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\bharanidharan.a\\appdata\\local\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\bharanidharan.a\\appdata\\local\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\bharanidharan.a\\appdata\\local\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.3)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\bharanidharan.a\\appdata\\local\\anaconda3\\lib\\site-packages (from langchain-core<0.3.0,>=0.2.32->langchain) (1.33)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in c:\\users\\bharanidharan.a\\appdata\\local\\anaconda3\\lib\\site-packages (from langchain-core<0.3.0,>=0.2.32->langchain) (23.2)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in c:\\users\\bharanidharan.a\\appdata\\local\\anaconda3\\lib\\site-packages (from langchain-core<0.3.0,>=0.2.32->langchain) (4.11.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\bharanidharan.a\\appdata\\local\\anaconda3\\lib\\site-packages (from langsmith<0.2.0,>=0.1.17->langchain) (0.27.0)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in c:\\users\\bharanidharan.a\\appdata\\local\\anaconda3\\lib\\site-packages (from langsmith<0.2.0,>=0.1.17->langchain) (3.10.7)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\bharanidharan.a\\appdata\\local\\anaconda3\\lib\\site-packages (from pydantic<3,>=1->langchain) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in c:\\users\\bharanidharan.a\\appdata\\local\\anaconda3\\lib\\site-packages (from pydantic<3,>=1->langchain) (2.20.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\bharanidharan.a\\appdata\\local\\anaconda3\\lib\\site-packages (from requests<3,>=2->langchain) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\bharanidharan.a\\appdata\\local\\anaconda3\\lib\\site-packages (from requests<3,>=2->langchain) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\bharanidharan.a\\appdata\\local\\anaconda3\\lib\\site-packages (from requests<3,>=2->langchain) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\bharanidharan.a\\appdata\\local\\anaconda3\\lib\\site-packages (from requests<3,>=2->langchain) (2024.6.2)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\bharanidharan.a\\appdata\\local\\anaconda3\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.1)\n",
      "Requirement already satisfied: anyio in c:\\users\\bharanidharan.a\\appdata\\local\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (4.2.0)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\bharanidharan.a\\appdata\\local\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (1.0.5)\n",
      "Requirement already satisfied: sniffio in c:\\users\\bharanidharan.a\\appdata\\local\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (1.3.0)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\bharanidharan.a\\appdata\\local\\anaconda3\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\bharanidharan.a\\appdata\\local\\anaconda3\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.32->langchain) (2.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ba4e83d2-ce52-4757-aaea-86d6d3942a7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain-openai in c:\\users\\bharanidharan.a\\appdata\\local\\anaconda3\\lib\\site-packages (0.1.22)\n",
      "Requirement already satisfied: langchain-core<0.3.0,>=0.2.33 in c:\\users\\bharanidharan.a\\appdata\\local\\anaconda3\\lib\\site-packages (from langchain-openai) (0.2.35)\n",
      "Requirement already satisfied: openai<2.0.0,>=1.40.0 in c:\\users\\bharanidharan.a\\appdata\\local\\anaconda3\\lib\\site-packages (from langchain-openai) (1.42.0)\n",
      "Requirement already satisfied: tiktoken<1,>=0.7 in c:\\users\\bharanidharan.a\\appdata\\local\\anaconda3\\lib\\site-packages (from langchain-openai) (0.7.0)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\bharanidharan.a\\appdata\\local\\anaconda3\\lib\\site-packages (from langchain-core<0.3.0,>=0.2.33->langchain-openai) (6.0.1)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\bharanidharan.a\\appdata\\local\\anaconda3\\lib\\site-packages (from langchain-core<0.3.0,>=0.2.33->langchain-openai) (1.33)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.75 in c:\\users\\bharanidharan.a\\appdata\\local\\anaconda3\\lib\\site-packages (from langchain-core<0.3.0,>=0.2.33->langchain-openai) (0.1.104)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in c:\\users\\bharanidharan.a\\appdata\\local\\anaconda3\\lib\\site-packages (from langchain-core<0.3.0,>=0.2.33->langchain-openai) (23.2)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in c:\\users\\bharanidharan.a\\appdata\\local\\anaconda3\\lib\\site-packages (from langchain-core<0.3.0,>=0.2.33->langchain-openai) (2.8.2)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in c:\\users\\bharanidharan.a\\appdata\\local\\anaconda3\\lib\\site-packages (from langchain-core<0.3.0,>=0.2.33->langchain-openai) (8.2.2)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in c:\\users\\bharanidharan.a\\appdata\\local\\anaconda3\\lib\\site-packages (from langchain-core<0.3.0,>=0.2.33->langchain-openai) (4.11.0)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\bharanidharan.a\\appdata\\local\\anaconda3\\lib\\site-packages (from openai<2.0.0,>=1.40.0->langchain-openai) (4.2.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\bharanidharan.a\\appdata\\local\\anaconda3\\lib\\site-packages (from openai<2.0.0,>=1.40.0->langchain-openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\bharanidharan.a\\appdata\\local\\anaconda3\\lib\\site-packages (from openai<2.0.0,>=1.40.0->langchain-openai) (0.27.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in c:\\users\\bharanidharan.a\\appdata\\local\\anaconda3\\lib\\site-packages (from openai<2.0.0,>=1.40.0->langchain-openai) (0.5.0)\n",
      "Requirement already satisfied: sniffio in c:\\users\\bharanidharan.a\\appdata\\local\\anaconda3\\lib\\site-packages (from openai<2.0.0,>=1.40.0->langchain-openai) (1.3.0)\n",
      "Requirement already satisfied: tqdm>4 in c:\\users\\bharanidharan.a\\appdata\\local\\anaconda3\\lib\\site-packages (from openai<2.0.0,>=1.40.0->langchain-openai) (4.66.4)\n",
      "Requirement already satisfied: regex>=2022.1.18 in c:\\users\\bharanidharan.a\\appdata\\local\\anaconda3\\lib\\site-packages (from tiktoken<1,>=0.7->langchain-openai) (2023.10.3)\n",
      "Requirement already satisfied: requests>=2.26.0 in c:\\users\\bharanidharan.a\\appdata\\local\\anaconda3\\lib\\site-packages (from tiktoken<1,>=0.7->langchain-openai) (2.32.2)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\bharanidharan.a\\appdata\\local\\anaconda3\\lib\\site-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.40.0->langchain-openai) (3.7)\n",
      "Requirement already satisfied: certifi in c:\\users\\bharanidharan.a\\appdata\\local\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.40.0->langchain-openai) (2024.6.2)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\bharanidharan.a\\appdata\\local\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.40.0->langchain-openai) (1.0.5)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\bharanidharan.a\\appdata\\local\\anaconda3\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai<2.0.0,>=1.40.0->langchain-openai) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\bharanidharan.a\\appdata\\local\\anaconda3\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.33->langchain-openai) (2.1)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in c:\\users\\bharanidharan.a\\appdata\\local\\anaconda3\\lib\\site-packages (from langsmith<0.2.0,>=0.1.75->langchain-core<0.3.0,>=0.2.33->langchain-openai) (3.10.7)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\bharanidharan.a\\appdata\\local\\anaconda3\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<0.3.0,>=0.2.33->langchain-openai) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in c:\\users\\bharanidharan.a\\appdata\\local\\anaconda3\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<0.3.0,>=0.2.33->langchain-openai) (2.20.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\bharanidharan.a\\appdata\\local\\anaconda3\\lib\\site-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain-openai) (2.0.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\bharanidharan.a\\appdata\\local\\anaconda3\\lib\\site-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain-openai) (2.2.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\bharanidharan.a\\appdata\\local\\anaconda3\\lib\\site-packages (from tqdm>4->openai<2.0.0,>=1.40.0->langchain-openai) (0.4.6)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -U langchain-openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "de342a46",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f0ad4c77",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(openai_api_key=openai.api_key, model_name=\"gpt-3.5-turbo\", max_tokens=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7bfa5d77",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema import AIMessage, HumanMessage,SystemMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "494f70fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bharanidharan.a\\AppData\\Local\\anaconda3\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:151: LangChainDeprecationWarning: The method `BaseChatModel.__call__` was deprecated in langchain-core 0.1.7 and will be removed in 1.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "reply = llm([\n",
    "SystemMessage(content='You are a helpful assistant.'),\n",
    "HumanMessage(content='what is a large language model')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e6e6092d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='A large language model is a type of artificial intelligence model that is trained on vast amounts of text data to understand and generate human language. These models can be used for various natural language processing tasks, such as text generation, translation, question answering, and more. Large language models have been gaining attention for their ability to produce human-like text and perform well on a wide range of language tasks. Examples of large language models include GPT-3 (Generative Pre-trained Transformer 3) and BERT', response_metadata={'token_usage': {'completion_tokens': 100, 'prompt_tokens': 23, 'total_tokens': 123}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'length', 'logprobs': None}, id='run-3ebe3b98-9130-4961-bfa1-ccc069251931-0')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "75863e83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A large language model is a type of artificial intelligence model that is trained on vast amounts of text data to understand and generate human language. These models can be used for various natural language processing tasks, such as text generation, translation, question answering, and more. Large language models have been gaining attention for their ability to produce human-like text and perform well on a wide range of language tasks. Examples of large language models include GPT-3 (Generative Pre-trained Transformer 3) and BERT\n"
     ]
    }
   ],
   "source": [
    "print(reply.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f2e94798",
   "metadata": {},
   "outputs": [],
   "source": [
    "reply = llm.generate([\n",
    "[SystemMessage(content='You are a helpful assistant.'),\n",
    "HumanMessage(content='what is a large language model')],\n",
    "[SystemMessage(content='You are an AI expert.'),\n",
    "HumanMessage(content='what is generative ai?')]\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "300817ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[ChatGeneration(text='A large language model is a type of artificial intelligence algorithm that is designed to understand and generate human language. These models are trained on vast amounts of text data to develop the ability to perform tasks such as text generation, language translation, sentiment analysis, and more. Large language models are becoming increasingly popular for various natural language processing applications due to their ability to understand and generate human-like text. Examples of large language models include GPT-3 (Generative Pre-trained Transformer 3) and BERT (', generation_info={'finish_reason': 'length', 'logprobs': None}, message=AIMessage(content='A large language model is a type of artificial intelligence algorithm that is designed to understand and generate human language. These models are trained on vast amounts of text data to develop the ability to perform tasks such as text generation, language translation, sentiment analysis, and more. Large language models are becoming increasingly popular for various natural language processing applications due to their ability to understand and generate human-like text. Examples of large language models include GPT-3 (Generative Pre-trained Transformer 3) and BERT (', response_metadata={'token_usage': {'completion_tokens': 100, 'prompt_tokens': 23, 'total_tokens': 123}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'length', 'logprobs': None}, id='run-21531782-a800-413a-ab48-9066d111c303-0'))],\n",
       " [ChatGeneration(text='Generative AI refers to a type of artificial intelligence that is capable of generating new content, such as images, text, or music, based on learning patterns and structures from existing data. These algorithms are designed to understand and replicate the patterns and characteristics of the data they have been trained on, allowing them to create new content that is similar in style or structure.\\n\\nGenerative AI has been used in a variety of applications, including creating artwork, generating realistic images of people or objects, and even composing music', generation_info={'finish_reason': 'length', 'logprobs': None}, message=AIMessage(content='Generative AI refers to a type of artificial intelligence that is capable of generating new content, such as images, text, or music, based on learning patterns and structures from existing data. These algorithms are designed to understand and replicate the patterns and characteristics of the data they have been trained on, allowing them to create new content that is similar in style or structure.\\n\\nGenerative AI has been used in a variety of applications, including creating artwork, generating realistic images of people or objects, and even composing music', response_metadata={'token_usage': {'completion_tokens': 100, 'prompt_tokens': 23, 'total_tokens': 123}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'length', 'logprobs': None}, id='run-8e40312d-252f-4814-8fa7-d345f801d8d6-0'))]]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reply.generations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ed8394d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[ChatGeneration(text='Generative AI refers to a type of artificial intelligence that is capable of generating new content, such as images, text, or music, based on learning patterns and structures from existing data. These algorithms are designed to understand and replicate the patterns and characteristics of the data they have been trained on, allowing them to create new content that is similar in style or structure.\\n\\nGenerative AI has been used in a variety of applications, including creating artwork, generating realistic images of people or objects, and even composing music', generation_info={'finish_reason': 'length', 'logprobs': None}, message=AIMessage(content='Generative AI refers to a type of artificial intelligence that is capable of generating new content, such as images, text, or music, based on learning patterns and structures from existing data. These algorithms are designed to understand and replicate the patterns and characteristics of the data they have been trained on, allowing them to create new content that is similar in style or structure.\\n\\nGenerative AI has been used in a variety of applications, including creating artwork, generating realistic images of people or objects, and even composing music', response_metadata={'token_usage': {'completion_tokens': 100, 'prompt_tokens': 23, 'total_tokens': 123}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'length', 'logprobs': None}, id='run-8e40312d-252f-4814-8fa7-d345f801d8d6-0'))]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reply.generations[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ceae5856",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Generative AI refers to a type of artificial intelligence that is capable of generating new content, such as images, text, or music, based on learning patterns and structures from existing data. These algorithms are designed to understand and replicate the patterns and characteristics of the data they have been trained on, allowing them to create new content that is similar in style or structure.\\n\\nGenerative AI has been used in a variety of applications, including creating artwork, generating realistic images of people or objects, and even composing music'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reply.generations[1][0].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "64f2fdb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "reply = llm.generate([\n",
    "[SystemMessage(content='You are a helpful assistant.'),\n",
    "HumanMessage(content='what is generative ai')],\n",
    "[SystemMessage(content='You are a helpful assistant.'),\n",
    "HumanMessage(content='improve this definition')]\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe840760",
   "metadata": {},
   "outputs": [],
   "source": [
    "reply.generations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4cbbf00",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
